---
title: "Create simple RDF data qube"
author: "PhuseSubTeamAnalysisResults@example.org"
date: "`r Sys.Date()`"
vignette: >
  %\VignetteIndexEntry{Create simple RDF data qube}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

## Introduction
This vignette shows how to create a very simple RDF data cube from 
- data 
- metadata  

## Setup
```{r}
library(rrdfqbcrnd0)
```

## Define data
```{r}
obsData<- data.frame(
  category=c("AA-group", "BB-group"),
  procedure=c("count", "count" ),
  factor=c("quantity", "quantity" ),
  unit=c("subject", "subject" ),
  denominator=c(" ", " "),
  measure=c( 123, 456 ),
  stringsAsFactors=FALSE  )
knitr::kable(obsData)
```

## Define meta data
```{r}
cubeMetadata<- data.frame(
  compType=c("dimension", "dimension", "dimension", "unit", "denominator", "measure", "metadata"),
  compName=c("category", "procedure", "factor", "attribute", "attribute", "measure", "domainName"),
  codeType=c("DATA", "DATA", "DATA", " ", " ", "<NA>","<NA>"),
  nciDomainValue=c(" "," "," "," ", " ", " "," "),
  compLabel=c("Category", "Statistical procedure", "Type of procedure", "Result", "Unit", "Denominator", "EXAMPLE"),
  Comment=c(" "," "," "," "," "," "," "),
  stringsAsFactors=FALSE  )
knitr::kable(cubeMetadata)
```

## Create RDF data cube

The RDF data cube for the data above is created using
```{r}
outcube<- BuildCubeFromDataFrames(cubeMetadata, obsData )
```

The RDF data cube is serialized in turtle format and stored as
```{r}
outcube
```

## Looking at the RDF data cube

Now look at the generated cubes by loading the turle files. Note: by specifying prefix the output contains is shown using the prefixes.
Note for future: This may be a disadvantage if the value of the prefix, say ds, changes.

```{r}
dataCubeFile<- outcube
```

The rest of the code only depends on the value of dataCubeFile.

```{r}
cube <- new.rdf()  # Initialize
load.rdf(dataCubeFile, format="TURTLE", appendTo= cube)
summarize.rdf(cube)

## TODO: reconsider the use of domain specific prefixes
dsdName<- GetDsdNameFromCube( cube )
domainName<- GetDomainNameFromCube( cube )
forsparqlprefix<- GetForSparqlPrefix( domainName )

```

The next statement shows the first 10 triples in the cube.
```{r, echo=FALSE}

cube.observations1.rq<- paste( forsparqlprefix,
'
select *
where {?s ?p ?o .}
limit 10
',
"\n"
)

cube.observations1<- sparql.rdf(cube, cube.observations1.rq  )
knitr::kable(head(cube.observations1, 10))
```

The next statement shows the first 30 triples in the cube, where the subject is a qb:Observation.
```{r}

cube.observations2.rq<-  paste( forsparqlprefix,
'
select *
where { ?s a qb:Observation ; ?p ?o .}
limit 30
',
"\n"                               
)

cube.observations2<- sparql.rdf(cube, cube.observations2.rq)
knitr::kable(head(cube.observations2, 10))

```

The SPARQL query for codelists are shown in the next output.
```{r, echo=FALSE}
codelists.rq<- GetCodeListSparqlQuery( forsparqlprefix, dsdName )
cat(codelists.rq)
```

Executing the SPARQL query gives the code list as a data frame.
```{r, echo=FALSE}
cube.codelists<- as.data.frame(sparql.rdf(cube, codelists.rq), stringsAsFactors=FALSE)

## TODO instead of gsub make a more straightforward way
## TODO this involves a new version of the ph.recode function
cube.codelists$vn<- gsub("prop:","",cube.codelists$p)
cube.codelists$clc<- gsub("code:","",cube.codelists$cl)
knitr::kable(print(cube.codelists[,c("vn", "clc", "prefLabel")]))

```

The dimensions are shown in the next output.
```{r}

cube.dimensions.rq<- paste(forsparqlprefix,
'
select * where
{ [] qb:dimension ?p .  }
',
"\n"
)
cube.dimensions<- as.data.frame(sparql.rdf(cube, cube.dimensions.rq), stringsAsFactors=FALSE)
knitr::kable(print(cube.dimensions))

```

And finally the SPARQL query for observations.
```{r, echo=FALSE}

cube.dimensionsattr<- sparql.rdf(cube,
  paste(forsparqlprefix,
"select * where { {[] qb:dimension ?p . } union {  ?p a qb:AttributeProperty . } }"
))

cube.observations.rq<-  paste( forsparqlprefix,
    "select * where {",
    "?s a qb:Observation  ;", "\n",
    paste("       qb:dataSet",  paste0( "ds:", "dataset", "-", domainName), " ;", sep=" ", collapse="\n"), "\n",
    paste0( cube.dimensionsattr, " ", sub("prop:", "?", cube.dimensionsattr), ";", collapse="\n"),
    "\n",
    "prop:measure      ?measure ;      \n",
    paste0( "optional{ ", sub("prop:", "?", cube.dimensionsattr), " ",
           "skos:prefLabel",
           " ",
           sub("prop:", "?", cube.dimensionsattr), "value" ,
           " . ", "}",
           collapse="\n"),
    "\n",
    "} ",
    "\n"
   )

```

This is the query for getting the observations
```{r}
cat(cube.observations.rq)
```

And finally the observations.
```{r}
cube.observations<- as.data.frame(sparql.rdf(cube, cube.observations.rq ), stringsAsFactors=FALSE)
knitr::kable(cube.observations[,c(paste0(sub("prop:", "", cube.dimensionsattr), "value"),"measure")])
```

The cube conformance with the integrity constraints can be checked using the RunQbIC function.
Note, this is not very interesting, as the cube is small.
```{r}
cdisc.rdf<- Load.cdisc.standards()
cubeData<- combine.rdf( cube, cdisc.rdf)
icres<- RunQbIC( cubeData, forsparqlprefix )
kable(icres)
```

```{r}
remove.triple(store,
  subject="http://example.org/Subject",
  predicate="http://example.org/Predicate",
  object="http://example.org/Object")
icres<- RunQbIC( cubeData, forsparqlprefix )
kable(icres)
```
